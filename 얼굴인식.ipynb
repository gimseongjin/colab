{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "얼굴인식",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM4t4WSjJlZCbJCX6wrJk74",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gimseongjin/colab/blob/main/%EC%96%BC%EA%B5%B4%EC%9D%B8%EC%8B%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcYaA5pFkMiY"
      },
      "source": [
        "# camera.py\n",
        "\n",
        "import cv2\n",
        "\n",
        "class VideoCamera(object):\n",
        "    def __init__(self):\n",
        "        # Using OpenCV to capture from device 0. If you have trouble capturing\n",
        "        # from a webcam, comment the line below out and use a video file\n",
        "        # instead.\n",
        "        self.video = cv2.VideoCapture(0)\n",
        "        # If you decide to use video.mp4, you must have this file in the folder\n",
        "        # as the main.py.\n",
        "        # self.video = cv2.VideoCapture('video.mp4')\n",
        "\n",
        "    def __del__(self):\n",
        "        self.video.release()\n",
        "\n",
        "    def get_frame(self):\n",
        "        # Grab a single frame of video\n",
        "        ret, frame = self.video.read()\n",
        "        return frame\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    cam = VideoCamera()\n",
        "    while True:\n",
        "        frame = cam.get_frame()\n",
        "\n",
        "        # show the frame\n",
        "        cv2.imshow(\"Frame\", frame)\n",
        "        key = cv2.waitKey(1) & 0xFF\n",
        "\n",
        "        # if the `q` key was pressed, break from the loop\n",
        "        if key == ord(\"q\"):\n",
        "            break\n",
        "\n",
        "    # do a bit of cleanup\n",
        "    cv2.destroyAllWindows()\n",
        "    print('finish')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PB-hoO8jkTPi"
      },
      "source": [
        "# face_recog.py\n",
        "\n",
        "import face_recognition\n",
        "import cv2\n",
        "import camera\n",
        "import os\n",
        "import numpy as np\n",
        "check = 0\n",
        "non_check = 0\n",
        "\n",
        "class FaceRecog():\n",
        "    def __init__(self):\n",
        "        # Using OpenCV to capture from device 0. If you have trouble capturing\n",
        "        # from a webcam, comment the line below out and use a video file\n",
        "        # instead.\n",
        "        self.camera = camera.VideoCamera()\n",
        "\n",
        "        self.known_face_encodings = []\n",
        "        self.known_face_names = []\n",
        "\n",
        "        # Load sample pictures and learn how to recognize it.\n",
        "        dirname = 'knowns'\n",
        "        files = os.listdir(dirname)\n",
        "        for filename in files:\n",
        "            name, ext = os.path.splitext(filename)\n",
        "            if ext == '.jpg':\n",
        "                self.known_face_names.append(name)\n",
        "                pathname = os.path.join(dirname, filename)\n",
        "                img = face_recognition.load_image_file(pathname)\n",
        "                face_encoding = face_recognition.face_encodings(img)[0]\n",
        "                self.known_face_encodings.append(face_encoding)\n",
        "\n",
        "        # Initialize some variables\n",
        "        self.face_locations = []\n",
        "        self.face_encodings = []\n",
        "        self.face_names = []\n",
        "        self.process_this_frame = True\n",
        "\n",
        "    def __del__(self):\n",
        "        del self.camera\n",
        "\n",
        "    def get_frame(self):\n",
        "        # Grab a single frame of video\n",
        "        frame = self.camera.get_frame()\n",
        "\n",
        "        # Resize frame of video to 1/4 size for faster face recognition processing\n",
        "        small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
        "\n",
        "        # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
        "        rgb_small_frame = small_frame[:, :, ::-1]\n",
        "\n",
        "        # Only process every other frame of video to save time\n",
        "        if self.process_this_frame:\n",
        "            # Find all the faces and face encodings in the current frame of video\n",
        "            self.face_locations = face_recognition.face_locations(rgb_small_frame)\n",
        "            self.face_encodings = face_recognition.face_encodings(rgb_small_frame, self.face_locations)\n",
        "\n",
        "            self.face_names = []\n",
        "            for face_encoding in self.face_encodings:\n",
        "                # See if the face is a match for the known face(s)\n",
        "                distances = face_recognition.face_distance(self.known_face_encodings, face_encoding)\n",
        "                min_value = min(distances)\n",
        "\n",
        "                # tolerance: How much distance between faces to consider it a match. Lower is more strict.\n",
        "                # 0.6 is typical best performance.\n",
        "                name = \"Unknown\"\n",
        "                if min_value < 0.6:\n",
        "                    index = np.argmin(distances)\n",
        "                    name = self.known_face_names[index]\n",
        "\n",
        "                self.face_names.append(name)\n",
        "\n",
        "        self.process_this_frame = not self.process_this_frame\n",
        "\n",
        "        # Display the results\n",
        "        for (top, right, bottom, left), name in zip(self.face_locations, self.face_names):\n",
        "            # Scale back up face locations since the frame we detected in was scaled to 1/4 size\n",
        "            top *= 4\n",
        "            right *= 4\n",
        "            bottom *= 4\n",
        "            left *= 4\n",
        "\n",
        "            # Draw a box around the face\n",
        "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
        "\n",
        "            # Draw a label with a name below the face\n",
        "            cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
        "            font = cv2.FONT_HERSHEY_DUPLEX\n",
        "            cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
        "\n",
        "        return frame\n",
        "\n",
        "    def get_jpg_bytes(self):\n",
        "        frame = self.get_frame()\n",
        "        # We are using Motion JPEG, but OpenCV defaults to capture raw images,\n",
        "        # so we must encode it into JPEG in order to correctly display the\n",
        "        # video stream.\n",
        "        ret, jpg = cv2.imencode('.jpg', frame)\n",
        "        return jpg.tobytes()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    cont = 0\n",
        "    \n",
        "    face_recog = FaceRecog()\n",
        "    print(face_recog.known_face_names)\n",
        "    while True:\n",
        "        frame = face_recog.get_frame()\n",
        "\n",
        "        # show the frame\n",
        "        cv2.imshow(\"Frame\", frame)\n",
        "        key = cv2.waitKey(1) & 0xFF\n",
        "\n",
        "        # if the `q` key was pressed, break from the loop\n",
        "        if key == ord(\"q\") & 0xFF:\n",
        "            break\n",
        "        elif key == ord(\"s\"):\n",
        "          #print(\" \") s눌러서 강제종료 될시 활성화 \n",
        "            name ='knowns/' + 'who' + str(cont) + '.jpg'\n",
        "            cv2.imwrite(name, frame)\n",
        "            cont += 1\n",
        "            \n",
        "    # do a bit of cleanup\n",
        "    cv2.destroyAllWindows()\n",
        "    print('finish')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}